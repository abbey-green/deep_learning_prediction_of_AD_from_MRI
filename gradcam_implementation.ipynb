{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8CCgb_sItVq"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "! pip install grad-cam\n",
        "import pytorch_grad_cam\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget, BinaryClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, raw):\n",
        "\n",
        "    # add a channel dimension to raw\n",
        "    shape = tuple(raw.shape)\n",
        "    raw = raw.reshape(shape[0], shape[1], shape[2], shape[3])\n",
        "#    raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
        "    # compute features\n",
        "    f = self.features(raw)\n",
        "    f = f.view(f.size(0), -1)\n",
        "\n",
        "    # classify\n",
        "    y = self.classifier(f)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "xkouAXvtJAna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the size of our images\n",
        "for x, y in train_dataset:\n",
        "  print(x.shape)\n",
        "  input_size = x.shape\n",
        "  break\n",
        "\n",
        "# create the model to train\n",
        "model = Vgg2D(input_size)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "# Target layer for grad cam\n",
        "cam = GradCAM(model=model, target_layers=[model.features[-4]])\n",
        "\n",
        "# create a loss\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# create an optimzer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "CpE2vKVgI85c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor,label = next(iter(test_dataloader))\n",
        "input_tensor,label = torch.tensor(input_tensor), torch.tensor(label)\n",
        "input_tensor.to(device), label.to(device)\n",
        "input_tensor = input_tensor / 255.0\n",
        "input_tensor = input_tensor.unsqueeze(0).to(torch.float32)\n",
        "input_tensor = input_tensor.permute(1, 0, 2,3)\n",
        "input_tensor.shape"
      ],
      "metadata": {
        "id": "HcqLmfAeIvk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_gradcam(model, input_tensor, target_class, target_layer, aug_smooth=False, eigen_smooth=False):\n",
        "\n",
        "    # Define the GradCAM object\n",
        "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
        "\n",
        "    # Define target\n",
        "    targets = [ClassifierOutputTarget(target_class)]\n",
        "\n",
        "    # Generate CAM\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets* input_tensor.size(0), aug_smooth=aug_smooth, eigen_smooth=eigen_smooth)\n",
        "\n",
        "    # Loop through batch and show Grad-CAM\n",
        "    for i in range(grayscale_cam.shape[0]):\n",
        "        grayscale_cam_i = grayscale_cam[i, :]\n",
        "        input_image_i = input_tensor[i].numpy().transpose(1, 2, 0)  # Convert to HWC format\n",
        "        input_image_i = np.repeat(input_image_i, 3, axis=2)  # Repeat grayscale image across 3 channels\n",
        "\n",
        "        # Ensure the image is in the correct range [0, 1]\n",
        "        input_image_i = (input_image_i - input_image_i.min()) / (input_image_i.max() - input_image_i.min())\n",
        "\n",
        "        visualization = show_cam_on_image(input_image_i, grayscale_cam_i, use_rgb=True)\n",
        "\n",
        "        # Visualize\n",
        "        plt.imshow(visualization)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have a model and input_tensor (batch of images) ready\n",
        "model = model\n",
        "input_tensor = input_tensor  # Example input tensor\n",
        "target_class = original_dataset.classes.index('AD')\n",
        "target_layer = model.features[39]  # Experiment with different layers\n",
        "\n",
        "visualize_gradcam(model, input_tensor, target_class, target_layer, aug_smooth=False, eigen_smooth=False)"
      ],
      "metadata": {
        "id": "oDQ2JJSuIv8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}